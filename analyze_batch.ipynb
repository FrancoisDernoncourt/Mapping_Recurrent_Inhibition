{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f57a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import torch\n",
    "from brian2 import *\n",
    "from sbi import utils, inference\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import getpass\n",
    "import psutil\n",
    "from dataclasses import dataclass, field, asdict\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa45d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from other files in the project\n",
    "from simulator import SimulationParameters, run_simulation\n",
    "from analyzer import AnalyzesParams, analyze_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f32a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental data\n",
    "# folder_with_data_to_analyze = 'C:\\\\Users\\\\franc\\\\Documents\\\\Mapping_Recurrent_Inhibition_minimal_datasets_to_run_scripts\\\\experimental_data'\n",
    "# Simulated data\n",
    "folder_with_data_to_analyze = 'C:\\\\Users\\\\franc\\\\Documents\\\\Mapping_Recurrent_Inhibition_minimal_datasets_to_run_scripts\\\\Example_small_simulation_batch'\n",
    "\n",
    "skip_analyses_already_performed = True # True # False\n",
    "analyze_sim_subset = [] # [0,1,2,3,4,5] # for debuggin purpose. Set to [] to analyze everything (normal behavior)\n",
    "repeat_analyses_for_different_MN_nb = False # True # check robustness/reproducibility of results when subsampling MNs. Will redo the analyses with N motor units, with N being each element of each nb_of_MUs_to_subsample\n",
    "nb_of_MUs_to_subsample = [5, 10, 15, 20, 25, 0] # used only if repeat_analyses_for_different_MN_nb = True. 0 is all motor units\n",
    "nb_of_subsampling_iterations = [30, 30, 30, 30, 30, 30] # has to be the same length as nb_of_MUs_to_subsample. Will repeat the analysis (for the selected nb of subsampled motor units) N times\n",
    "# # ANALYZIS PARAMETERS FOR SIMULATED DATA\n",
    "analyzes_params = AnalyzesParams(is_simulation=True, # True,\n",
    "                                 remove_discontinuous_MNs=False,\n",
    "                                 select_random_subset_of_MUs_per_pool_for_analyses=0, # 0 = all motor units\n",
    "                                 get_coherence = True, # True,\n",
    "                                 coherence_between_CST_and_common_input = True,\n",
    "                                 coherence_calc_max_iteration_nb_per_group_size=100,\n",
    "                                 coherence_max_freq = 150,\n",
    "                                 coherence_output_figures = True, # This is quite long to run! But it generates per-MN figure of the cross-histograms (in both direction, with MN as reference or MN as comparison) for visual inspection\n",
    "                                 get_cross_histogram_measures = True, # True\n",
    "                                 cross_histogram_ignore_homonymous_pool=False, # if True, do not perform the analysis on MU pairs coming from the same pool (saves time when doing the analysis only for the between-pool case)\n",
    "                                 cross_histogram_ignore_heteronymous_pool=False, # if True, do not perform the analysis on MU pairs coming from different pools (saves time when doing the analysis only for the within-pool case)\n",
    "                                 cross_histogram_output_figures=False, # This is quite long to run!\n",
    "                                 # But it generates per-MN figure of the cross-histograms (in both direction, with MN as reference or MN as comparison) for visual inspection\n",
    "                                 cross_histogram_save_cross_hists=True, # Saving all histograms/probability distributions generated for the analysis takes up memory space but allows for plotting later.\n",
    "                                 cross_histogram_measures_min_plateau = 0.02, # in seconds. 0.02 is 10ms on each side of t=0\n",
    "                                 cross_histogram_measures_min_spikes=1*1e3, # Filtering later, during SBI\n",
    "                                 # ^ A minimum amount like 1e3 allows to avoid performing the analysis when heteronymous or homonymous pairs are to be ignored (cross_histogram_ignore_homonymous_pool == True or cross_histogram_ignore_homonymous_pool == True)\n",
    "                                 cross_histogram_measures_min_r2=0, # Filtering later, during SBI\n",
    "                                 cross_histogram_measures_null_distrib_nb_iter=0) # if 0, no p values calculated from distribution of troughs (makes it faster)\n",
    "\n",
    "# ANALYZIS PARAMETERS FOR EXPERIMENTAL DATA\n",
    "# analyzes_params = AnalyzesParams(is_simulation=False,\n",
    "#                                  remove_discontinuous_MNs=False,\n",
    "#                                  get_firing_rates = False,\n",
    "#                                  get_ground_truth_RI_connectivity = False,\n",
    "#                                  get_graph_theory_connectivity_measures = False,\n",
    "#                                  get_cross_histogram_measures=True,\n",
    "#                                  cross_histogram_output_figures=False, # This is quite long to run!\n",
    "#                                  # But it generates per-MN figure of the cross-histograms (in both direction, with MN as reference or MN as comparison) for visual inspection\n",
    "#                                  cross_histogram_save_cross_hists=True, # Saving all histograms/probability distributions generated for the analysis takes up memory space but allows for plotting later.\n",
    "#                                  # ^ if set to True, then cross_histogram_output_figures must also be True\n",
    "#                                  cross_histogram_measures_min_plateau = 0.02, # in seconds. 0.02 is 10ms on each side of t=0\n",
    "#                                  cross_histogram_measures_min_spikes=1*1e3, # Filtering later, during analysis\n",
    "#                                  cross_histogram_measures_min_r2=0, # Filtering later, during analysis\n",
    "#                                  cross_histogram_measures_null_distrib_nb_iter=100, # for p values calculations\n",
    "#                                  get_coherence = False)\n",
    "\n",
    "analyze_parallel_cpus = 16 # Modify according to your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae704c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analyzes parameters as a pkl file in the folder containing all the simulations from the batch\n",
    "# Saves the fixed analyzis parameters (so doesn't save the subsampling part of the parameters)\n",
    "pkl_path = f\"{folder_with_data_to_analyze}\\\\analyzes_parameters.pkl\"\n",
    "with open(pkl_path, 'wb') as f:\n",
    "    pickle.dump(asdict(analyzes_params), f)\n",
    "\n",
    "print(f\"✅ Saved analyses parameters to {pkl_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c02da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hdf5_files(root_folder, skip_already_done_analyses=True):\n",
    "    \"\"\"\n",
    "    Return a list of all .h5 files under root_folder (including subdirectories).\n",
    "    If skip_already_done_analyses is True, any .h5 file that lives in a directory\n",
    "    containing \"analysis_output.pkl\" will be omitted from the result.\n",
    "    \"\"\"\n",
    "    root = Path(root_folder)\n",
    "    h5_paths = list(root.rglob(\"*.h5\"))\n",
    "    \n",
    "    if not skip_already_done_analyses:\n",
    "        return [str(p) for p in h5_paths]\n",
    "    \n",
    "    filtered = []\n",
    "    for p in h5_paths:\n",
    "        # check if this .h5’s parent directory has \"analysis_output.pkl\"\n",
    "        if (p.parent / \"analysis_output.pkl\").exists():\n",
    "            # skip this file\n",
    "            continue\n",
    "        filtered.append(str(p))\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for parallelization\n",
    "from joblib import Parallel, delayed\n",
    "from brian2 import prefs, device\n",
    "import logging\n",
    "\n",
    "# # # Function to make sure to terminate any Python process that runs in the background (this can happen when the kernel crashes during the parallelized computations)\n",
    "def kill_other_python_processes():\n",
    "    me = os.getpid()\n",
    "    user = getpass.getuser()\n",
    "    for proc in psutil.process_iter(['pid', 'name', 'username']):\n",
    "        try:\n",
    "            # only consider Python executables run by this user\n",
    "            if proc.info['username'] != user:\n",
    "                continue\n",
    "            name = proc.info['name'].lower()\n",
    "            # match python, pythonw, python3, etc\n",
    "            if name.startswith('python'):\n",
    "                pid = proc.info['pid']\n",
    "                if pid != me:\n",
    "                    proc.kill()   # or proc.terminate()\n",
    "                    print(f\"{name} process terminated\")\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied):\n",
    "            pass\n",
    "if __name__ == '__main__':\n",
    "    kill_other_python_processes()\n",
    "    # now safe to start joblib Parallel(...)\n",
    "\n",
    "# --- Helper to wrap a single simulation and then reset Brian2 ---\n",
    "def _run_and_reset(params):\n",
    "    # params must be a SimulationParameters instance\n",
    "    out = run_simulation(params)\n",
    "    # after each run, reset Brian2’s magic network so the next worker starts fresh\n",
    "    device.reinit()     # clears all Brian2 objects\n",
    "    device.activate()   # re–activate the default runtime device\n",
    "    return out\n",
    "\n",
    "# # # PARALLEL SIMULATIONS\n",
    "def parallel_simulate(params_prior_list, n_jobs=8):\n",
    "    \"\"\"\n",
    "    params_prior_list : list of SimulationParameters\n",
    "    n_jobs      :       number of parallel workers\n",
    "    \"\"\"\n",
    "    # Note: `prefer=\"processes\"` is the default for `n_jobs>1`\n",
    "    sim_outputs = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_run_and_reset)(p) for p in params_prior_list)\n",
    "    return sim_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # PARALLEL ANALYSIS\n",
    "# Analyzes_to_run should be a list of AnalyzesParams objects (can be a list with a single object if running the same analyses each time)\n",
    "def parallel_analyze(files_to_analyze, analyzes_to_run, n_jobs=8):\n",
    "    \"\"\"\n",
    "    sim_outputs : list of simulation outputs as hdf5 files (path)\n",
    "    n_jobs      : number of parallel workers\n",
    "    \"\"\"\n",
    "    # Note: `prefer=\"processes\"` is the default for `n_jobs>1`\n",
    "    if (len(analyzes_to_run) == 1): \n",
    "        if isinstance(files_to_analyze, str): # If there is only one file to analyze (a string)\n",
    "            print(f\"Running a single analysis on a single file\")\n",
    "            analysis_outputs = analyze_data(files_to_analyze, analyzes_to_run[0])\n",
    "        elif isinstance(files_to_analyze, list): # Several files to analyze (strings in a list)\n",
    "            print(f\"Running a single analysis on {len(files_to_analyze)} file(s)\")\n",
    "            analysis_outputs = Parallel(n_jobs=n_jobs)(\n",
    "                delayed(analyze_data)(f, analyzes_to_run[0])\n",
    "                for f in files_to_analyze)\n",
    "        else:\n",
    "            analysis_outputs = None\n",
    "            print(\"No valid type of analysis_outputs\")\n",
    "    else: #elif (len(analyzes_to_run) > 1): # will run several analyses per files - parallelize the analyzis iterations instead of the files to analyses\n",
    "        if isinstance(files_to_analyze, str): # If there is only one file to analyze (a string)\n",
    "            print(f\"Running {len(analyzes_to_run)} analyses on a single file\")\n",
    "            analysis_outputs = Parallel(n_jobs=n_jobs)(\n",
    "                delayed(analyze_data)(files_to_analyze, analysis_i)\n",
    "                for analysis_i in analyzes_to_run)\n",
    "        elif isinstance(files_to_analyze, list): # Several files to analyze (strings in a list)\n",
    "            print(f\"Running {len(analyzes_to_run)} analyses on {len(files_to_analyze)} file(s)\")\n",
    "            for file_to_analyze_i in range(len(files_to_analyze)):\n",
    "                analysis_outputs = Parallel(n_jobs=n_jobs)(\n",
    "                    delayed(analyze_data)(files_to_analyze[file_to_analyze_i], analysis_i)\n",
    "                    for analysis_i in analyzes_to_run)\n",
    "        else:\n",
    "            analysis_outputs = None\n",
    "            print(\"No valid type of analysis_outputs\")\n",
    "        \n",
    "        # for analyzis_element_i in range(len(analyzes_to_run)):\n",
    "        #     for analyzis_iter in range(nb_of_subsampling_iterations[analyzis_element_i]):\n",
    "        #         if isinstance(files_to_analyze, str): # If there is only one file to analyze (a string)\n",
    "        #             analysis_outputs = analysis_outputs = analyze_data(files_to_analyze, analyzes_to_run[0])\n",
    "        #         else: # Several files to analyze (strings in a list)\n",
    "        #             analysis_outputs = Parallel(n_jobs=n_jobs)(\n",
    "        #                 delayed(analyze_data)(f, analyzes_to_run[analyzis_element_i])\n",
    "        #                 for f in files_to_analyze)\n",
    "\n",
    "    return analysis_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fd18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture progres (in .log file) directly in the notebook cell\n",
    "from threading import Thread, Event\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "_tail_thread = None\n",
    "_tail_stop = threading.Event()\n",
    "\n",
    "def start_tail(logfile=\"simulations_progress_log.log\", poll_interval=1.0):\n",
    "    \"\"\"\n",
    "    Spawn a thread that prints only the log‐lines whose timestamp\n",
    "    is ≥ the moment you called start_tail(), and strips off everything\n",
    "    before the log‐level (INFO:, WARNING:, ERROR:, etc.).\n",
    "    \"\"\"\n",
    "    global _tail_thread, _tail_stop\n",
    "\n",
    "    # make sure the file exists (touch it)\n",
    "    open(logfile, \"a\").close()\n",
    "\n",
    "    # remember \"now\" and clear any previous stop flag\n",
    "    start_dt = datetime.now()\n",
    "    _tail_stop.clear()\n",
    "\n",
    "    def _tail_loop():\n",
    "        level_re = re.compile(r'\\b(?:DEBUG|INFO|WARNING|ERROR|CRITICAL)\\b:\\s*')\n",
    "        with open(logfile, \"r\", encoding=\"utf-8\") as f:\n",
    "            # seek to end: we only want new lines\n",
    "            f.seek(0, 2)\n",
    "            while not _tail_stop.is_set():\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    time.sleep(poll_interval)\n",
    "                    continue\n",
    "\n",
    "                # try to parse timestamp at the very start\n",
    "                try:\n",
    "                    ts_str = \" \".join(line.split(\" \")[:2]).rstrip(\",\")\n",
    "                    ts = datetime.strptime(ts_str, \"%Y-%m-%d %H:%M:%S,%f\")\n",
    "                except Exception:\n",
    "                    ts = start_dt  # force print for non‐timestamped lines\n",
    "\n",
    "                if ts >= start_dt:\n",
    "                    # strip off everything before the level marker\n",
    "                    m = level_re.search(line)\n",
    "                    if m:\n",
    "                        print(line[m.start():], end=\"\")\n",
    "                    else:\n",
    "                        print(line, end=\"\")\n",
    "\n",
    "    # fire up the thread (only one at a time)\n",
    "    if _tail_thread is None or not _tail_thread.is_alive():\n",
    "        _tail_thread = threading.Thread(target=_tail_loop, daemon=True)\n",
    "        _tail_thread.start()\n",
    "    else:\n",
    "        print(\"Tail already running; call `end_tail()` first if you want to restart.\")\n",
    "\n",
    "def stop_tail():\n",
    "    \"\"\"Stop the background tail thread.\"\"\"\n",
    "    _tail_stop.set()\n",
    "    if _tail_thread:\n",
    "        _tail_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60711ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_output_files = find_hdf5_files(folder_with_data_to_analyze, skip_already_done_analyses=skip_analyses_already_performed)\n",
    "if (len(analyze_sim_subset) > 0):\n",
    "    simulation_output_files = [simulation_output_files[i] for i in analyze_sim_subset]\n",
    "print(f\"Nb of files to analyze = {len(simulation_output_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzes_params_list = []\n",
    "if repeat_analyses_for_different_MN_nb: # Create a list of simulation params, with the only change being the nb of MUs to subsample\n",
    "    element_i = -1\n",
    "    for subsample_i in nb_of_MUs_to_subsample:\n",
    "        element_i += 1\n",
    "        for iteration_i in range(nb_of_subsampling_iterations[element_i]):\n",
    "            params_copy = copy.deepcopy(analyzes_params) # make a fresh copy each time\n",
    "            params_copy.select_random_subset_of_MUs_per_pool_for_analyses = subsample_i\n",
    "            if subsample_i == 0:\n",
    "                params_copy.analysis_output_name = f\"subsample_all_MNs_iter{iteration_i}\"\n",
    "            else:\n",
    "                params_copy.analysis_output_name = f\"subsample_{subsample_i}MNs_iter{iteration_i}\"\n",
    "            # print(analyzes_params_temp.analysis_output_name)\n",
    "            analyzes_params_list.append(params_copy)\n",
    "else: # Create a one-element list\n",
    "    analyzes_params_list.append(analyzes_params)\n",
    "\n",
    "print(f\"Nb of analyzes to perform on each file = {len(analyzes_params_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b98a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not repeat_analyses_for_different_MN_nb: # skip this part if running the analyses several times for each MN subsample\n",
    "    start_tail()\n",
    "    analyzis_output = parallel_analyze(simulation_output_files, [analyzes_params], n_jobs=analyze_parallel_cpus)\n",
    "    time.sleep(1)  # give it a moment to print the last lines\n",
    "    stop_tail()\n",
    "else:\n",
    "    start_tail()\n",
    "    analyzis_output = parallel_analyze(simulation_output_files, analyzes_params_list, n_jobs=analyze_parallel_cpus)\n",
    "    time.sleep(1)  # give it a moment to print the last lines\n",
    "    stop_tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapping_RI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
