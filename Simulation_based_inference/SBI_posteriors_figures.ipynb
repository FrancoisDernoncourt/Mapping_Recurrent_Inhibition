{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cmasher as cmr\n",
    "import os\n",
    "import re\n",
    "from matplotlib.colors import to_rgb\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = {\n",
    "    \"single_muscles\": {\n",
    "        \"path\": \"C:\\\\Users\\\\franc\\\\Documents\\\\GitHub\\\\Mapping_Recurrent_Inhibition\\\\Simulation_based_inference\\\\saved_posterior_density_estimators\\\\single_muscles_density_estimator\",\n",
    "        \"posterior_by_subject\": None,\n",
    "        \"posterior_subjects_aggregated\": None,\n",
    "    },\n",
    "    \"muscle_pairs\": {\n",
    "        \"path\": \"C:\\\\Users\\\\franc\\\\Documents\\\\GitHub\\\\Mapping_Recurrent_Inhibition\\\\Simulation_based_inference\\\\saved_posterior_density_estimators\\\\paired_muscles_density_estimator\",\n",
    "        \"posterior_by_subject\": None,\n",
    "        \"posterior_subjects_aggregated\": None,\n",
    "    }\n",
    "}\n",
    "save_path = f\"Posterior inference output figures\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "direction = \"inhibited\"  # or \"inhibiting\"\n",
    "posterior_by_subject_filename = \"posterior_samples_each_subject_df.csv\"\n",
    "posterior_subjects_aggregated_filename = \"posterior_samples_subjects_grouped_df.csv\"\n",
    "\n",
    "dims = [\n",
    "    \"disynpatic_inhib_connections_desired_MN_MN\",\n",
    "    \"common_input_std\",\n",
    "    \"excitatory_input_baseline\",\n",
    "    \"between_pool_excitatory_input_correlation\"\n",
    "]\n",
    "\n",
    "# Aliases from your two sources → \"canonical\" dim names\n",
    "dim_aliases = {\n",
    "    \"disynpatic_inhib_connections_desired_MN_MN\": [\"disynpatic_inhib_connections_desired_MN_MN_other_pool\"],\n",
    "    \"common_input_std\":  [\"common_input_std\"],\n",
    "    \"excitatory_input_baseline\": [\"excitatory_input_baseline\"],\n",
    "    \"between_pool_excitatory_input_correlation\": [\"between_pool_excitatory_input_correlation\"],\n",
    "}\n",
    "\n",
    "dims_to_display = [\n",
    "    \"disynpatic_inhib_connections_desired_MN_MN\", \n",
    "    \"common_input_std\",\n",
    "]\n",
    "\n",
    "# Limits for canonical dims (based on your priors) => used for 0-1 normalization relative to priors\n",
    "lims_by_dim = {\n",
    "    # single-muscle\n",
    "    \"disynpatic_inhib_connections_desired_MN_MN\": (0, 3),\n",
    "    \"common_input_std\": (0, 7e3),\n",
    "    \"excitatory_input_baseline\": (20e3, 70e3),\n",
    "    # pair (alias; will map back to canonical if needed)\n",
    "    \"disynpatic_inhib_connections_desired_MN_MN_other_pool\": (0, 3),\n",
    "    \"between_pool_excitatory_input_correlation\": (0, 1),\n",
    "}\n",
    "\n",
    "####  DISPLAY SETTINGS  ####\n",
    "\n",
    "colors_dict = {\n",
    "    \"VL<->VL\": \"#D62728\",\n",
    "    \"VL<->VM\": \"#FF5101\", # \"#FF9201\",\n",
    "    # \"VM<->VL\": \"#FFC400\", # \"#FF9201\",\n",
    "    \"VM<->VM\": \"#FFC400\",\n",
    "    \"TA<->TA\": \"#00C71B\",\n",
    "    \"FDI<->FDI\": \"#14BFA8\",\n",
    "    \"GM<->GM\": \"#2489DC\",\n",
    "    \"GM<->SOL\": \"#5243FF\", # \"#7D74EC\",\n",
    "    # \"SOL<->GM\": \"#BB86ED\", # \"#7D74EC\",\n",
    "    \"SOL<->SOL\": \"#BB86ED\",\n",
    "\n",
    "    \"VL\": \"#D62728\",\n",
    "    \"VM\": \"#FFC400\",\n",
    "    \"TA\": \"#00C71B\",\n",
    "    \"FDI\": \"#14BFA8\",\n",
    "    \"GM\": \"#2489DC\",\n",
    "    \"SOL\": \"#BB86ED\",\n",
    "\n",
    "    \"GM<-SOL\": \"#5243FF\", # \"#7D74EC\",\n",
    "    \"GM inhibited by SOL\": \"#5243FF\", # \"#7D74EC\",\n",
    "    # \"SOL<-GM\": \"#5243FF\", # \"#7D74EC\",\n",
    "    # \"SOL inhibited by GM\": \"#5243FF\", # \"#7D74EC\",\n",
    "    # \"GM->SOL\": \"#5243FF\", # \"#7D74EC\",\n",
    "    # \"GM inhibiting SOL\": \"#5243FF\", # \"#7D74EC\",\n",
    "    # \"SOL->GM\": \"#5243FF\", # \"#7D74EC\",\n",
    "    # \"SOL inhibiting GM\": \"#5243FF\", # \"#7D74EC\",\n",
    "\n",
    "    \"VL<-VM\": \"#FF5101\", # \"#FF9201\",\n",
    "    \"VL inhibited by VM\": \"#FF5101\", # \"#FF9201\",\n",
    "    # \"VM<-VL\": \"#FF5101\", # \"#FF9201\",\n",
    "    # \"VM inhibited by VL\": \"#FF5101\", # \"#FF9201\",\n",
    "    # \"VL->VM\": \"#FF5101\", # \"#FF9201\",\n",
    "    # \"VL inhibiting VM\": \"#FF5101\", # \"#FF9201\",\n",
    "    # \"VM->VL\": \"#FF5101\", # \"#FF9201\",\n",
    "    # \"VM inhibiting VL\": \"#FF5101\", # \"#FF9201\",\n",
    "}\n",
    "\n",
    "order_display = { # Only used for p delta heatmap plots\n",
    "    \"VL\": \"VL\",\n",
    "    \"VL<->VL\": \"VL\",\n",
    "    \"VL<-VL\": \"VL\",\n",
    "    \"VL->VL\": \"VL\",\n",
    "\n",
    "    \"VM<-VL\": \"VM inhibited by VL\",\n",
    "    \"VL->VM\": \"VL inhibiting VM\",\n",
    "\n",
    "    \"VM->VL\": \"VM inhibiting VL\",\n",
    "    \"VL<-VM\": \"VL inhibited by VM\",\n",
    "\n",
    "    \"VM\": \"VM\",\n",
    "    \"VM<->VM\": \"VM\",\n",
    "    \"VM<-VM\": \"VM\",\n",
    "    \"VM->VM\": \"VM\",\n",
    "\n",
    "    \"TA\": \"TA\",\n",
    "    \"TA<->TA\": \"TA\",\n",
    "    \"TA<-TA\": \"TA\",\n",
    "    \"TA->TA\": \"TA\",\n",
    "\n",
    "    \"FDI\": \"FDI\",\n",
    "    \"FDI<->FDI\": \"FDI\",\n",
    "    \"FDI<-FDI\": \"FDI\",\n",
    "    \"FDI->FDI\": \"FDI\",\n",
    "\n",
    "    \"GM\": \"GM\",\n",
    "    \"GM<->GM\": \"GM\",\n",
    "    \"GM<-GM\": \"GM\",\n",
    "    \"GM->GM\": \"GM\",\n",
    "\n",
    "    \"SOL<-GM\": \"SOL inhibited by GM\",\n",
    "    \"GM->SOL\": \"GM inhibiting SOL\",\n",
    "\n",
    "    \"GM<-SOL\": \"GM inhibited by SOL\",\n",
    "    \"SOL->GM\": \"SOL inhibiting GM\",\n",
    "\n",
    "    \"SOL\": \"SOL\",\n",
    "    \"SOL<->SOL\": \"SOL\",\n",
    "    \"SOL<-SOL\": \"SOL\",\n",
    "    \"SOL->SOL\": \"SOL\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd84bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Helpers\n",
    "# -----------------------------------------\n",
    "def _derive_muscle_label(muscle_pair: str, direction: str) -> str:\n",
    "    \"\"\"\n",
    "    from 'A<->B' and a direction ('inhibited' or 'inhibiting'),\n",
    "    return:\n",
    "      - 'A' if A == B\n",
    "      - 'A<-B' if direction == 'inhibited' and A != B\n",
    "      - 'A->B' if direction == 'inhibiting' and A != B\n",
    "    \"\"\"\n",
    "    if not isinstance(muscle_pair, str) or \"<->\" not in muscle_pair:\n",
    "        return str(muscle_pair)\n",
    "\n",
    "    left, right = muscle_pair.split(\"<->\", 1)\n",
    "    left, right = left.strip(), right.strip()\n",
    "\n",
    "    if left == right:\n",
    "        return left\n",
    "    if direction == \"inhibited\":\n",
    "        return f\"{left}<-{right}\"\n",
    "    elif direction == \"inhibiting\":\n",
    "        return f\"{left}->{right}\"\n",
    "    else:\n",
    "        # fallback: keep original\n",
    "        return f\"{left}<->{right}\"\n",
    "\n",
    "def _read_and_tag_csv(path, fname, source_key, level, direction):\n",
    "    f = os.path.join(path, fname)\n",
    "    if not os.path.exists(f):\n",
    "        print(f\"Warning: {f!r} not found, skipping\")\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "    # Tag origin\n",
    "    df[\"source_key\"] = source_key                 # \"single_muscles\" or \"muscle_pairs\"\n",
    "    df[\"level\"] = level                           # \"by_subject\" or \"subjects_aggregated\"\n",
    "    df[\"direction\"] = direction                   # global direction used to build 'muscle' label\n",
    "\n",
    "    # Identity columns\n",
    "    if \"subject\" not in df.columns:\n",
    "        df[\"subject\"] = \"ALL\"\n",
    "\n",
    "    if \"intensity\" in df.columns:\n",
    "        df[\"intensity\"] = pd.to_numeric(df[\"intensity\"], errors=\"coerce\")\n",
    "\n",
    "    # Must have muscle_pair (your files do); if not, create a placeholder\n",
    "    if \"muscle_pair\" not in df.columns:\n",
    "        df[\"muscle_pair\"] = np.nan\n",
    "\n",
    "    # 'muscle' label derived from 'muscle_pair' + direction\n",
    "    df[\"muscle\"] = df[\"muscle_pair\"].astype(str).apply(lambda s: _derive_muscle_label(s, direction))\n",
    "\n",
    "    # Scope: single if A==B, else pair\n",
    "    def _scope_from_pair(p):\n",
    "        if not isinstance(p, str) or \"<->\" not in p:\n",
    "            return \"unknown\"\n",
    "        a, b = [t.strip() for t in p.split(\"<->\", 1)]\n",
    "        return \"single\" if a == b else \"pair\"\n",
    "\n",
    "    df[\"scope\"] = df[\"muscle_pair\"].astype(str).apply(_scope_from_pair)\n",
    "    return df\n",
    "\n",
    "def normalize_columns_inplace(df, lims_by_dim, suffix=None, clip=True):\n",
    "    \"\"\"\n",
    "    Normalize chosen columns to [0,1] using lims_by_dim={col: (low, high)}.\n",
    "    If suffix is provided (e.g., '_unit'), writes to new columns; otherwise overwrites in place.\n",
    "    \"\"\"\n",
    "    for col, (lo, hi) in lims_by_dim.items():\n",
    "        if col in df.columns:\n",
    "            width = (hi - lo) if (hi is not None and lo is not None) else None\n",
    "            if width is None or width == 0:\n",
    "                continue\n",
    "            vals = (df[col].astype(float) - lo) / width\n",
    "            if clip:\n",
    "                vals = vals.clip(0.0, 1.0)\n",
    "            if suffix:\n",
    "                df[col + suffix] = vals\n",
    "            else:\n",
    "                df[col] = vals\n",
    "    return df\n",
    "\n",
    "# -----------------------------------------\n",
    "# Build a single unified DF\n",
    "# -----------------------------------------\n",
    "frames_all = []\n",
    "\n",
    "for key_i, val_i in all_files.items():\n",
    "    path = val_i.get(\"path\")\n",
    "    if not path:\n",
    "        continue\n",
    "\n",
    "    # by-subject\n",
    "    df_bs = _read_and_tag_csv(path, posterior_by_subject_filename, source_key=key_i,\n",
    "                              level=\"by_subject\", direction=direction)\n",
    "    if df_bs is not None:\n",
    "        frames_all.append(df_bs)\n",
    "\n",
    "    # aggregated across subjects\n",
    "    df_ag = _read_and_tag_csv(path, posterior_subjects_aggregated_filename, source_key=key_i,\n",
    "                              level=\"subjects_aggregated\", direction=direction)\n",
    "    if df_ag is not None:\n",
    "        frames_all.append(df_ag)\n",
    "\n",
    "df_all_posteriors = pd.concat(frames_all, ignore_index=True, sort=False) if frames_all else pd.DataFrame()\n",
    "\n",
    "# Normalize desired columns (overwrite, or write to new columns with suffix)\n",
    "# Overwrite in place:\n",
    "normalize_columns_inplace(df_all_posteriors, lims_by_dim, suffix=None, clip=True)\n",
    "# If you prefer to keep originals: use suffix=\"_unit\" instead of None.\n",
    "# normalize_columns_inplace(df_all_posteriors, lims_by_dim, suffix=\"_unit\", clip=True)\n",
    "\n",
    "# Reorder a few meta columns first\n",
    "meta_first = [\"source_key\", \"level\", \"scope\", \"direction\", \"subject\", \"muscle\", \"muscle_pair\", \"intensity\"]\n",
    "cols = [c for c in meta_first if c in df_all_posteriors.columns] + \\\n",
    "       [c for c in df_all_posteriors.columns if c not in meta_first]\n",
    "df_all_posteriors = df_all_posteriors[cols]\n",
    "\n",
    "print(df_all_posteriors.shape, \"rows x cols\")\n",
    "print(df_all_posteriors[[\"source_key\",\"level\",\"scope\"]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_posteriors # check result of previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb173ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pooled_subjects = df_all_posteriors[df_all_posteriors['level']==\"subjects_aggregated\"]\n",
    "df_each_subject = df_all_posteriors[df_all_posteriors['level']!=\"subjects_aggregated\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61272483",
   "metadata": {},
   "source": [
    "# Pairplots (2D density plot + marginal 1D densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47684c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_muscle_pairplot_scatter_kde(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    # Column harmonization:\n",
    "    dim_aliases: dict[str, list[str]],\n",
    "    dims_to_display: list[str],          # EXACTLY [X_dim, Y_dim] → X is bottom-right, Y is top-left\n",
    "    # Coloring & grouping:\n",
    "    hue_by: str,                          # e.g., \"muscle\"\n",
    "    muscle_colors: dict[str, str],        # map hue value -> hex\n",
    "    stratify_by: list[str] | None = None, # e.g., [\"intensity\"]\n",
    "    # Prior bounds for normalization:\n",
    "    lims_by_dim: dict[str, tuple] | None = None,\n",
    "    normalize_to_unit: bool = True,\n",
    "    assume_pre_normalized: bool = False,\n",
    "    # Style knobs:\n",
    "    show_scatter: bool = True,            # turn off points to show density-only with fills\n",
    "    point_size: float = 26,\n",
    "    scatter_alpha: float = 0.30,\n",
    "    kde1d_lw: float = 2.2,\n",
    "    kde2d_levels: tuple = (0.3, 0.6, 0.9),  # mass levels\n",
    "    kde2d_lw: float = 1.6,\n",
    "    kde2d_alpha: float = 1.0,\n",
    "    kde2d_grid: int = 220,\n",
    "    darker_mix: float = 0.5,              # 0..1: 0 = original color, 1 = black (for contour lines)\n",
    "    # NEW: smoothing controls\n",
    "    kde1d_bw: float | str | None = \"scott\",  # \"scott\", \"silverman\", float multiplier, or callable\n",
    "    kde2d_bw: float | str | None = \"scott\",  # idem, for the joint 2-D KDE\n",
    "    # Density-only fills (when show_scatter=False):\n",
    "    kde2d_fill_alpha: float = 0.10,       # per-pass alpha for recursive fill\n",
    "    # Axes control (optional):\n",
    "    xlim: tuple | None = None,\n",
    "    ylim: tuple | None = None,\n",
    "    # IO:\n",
    "    save_dir: str = \".\",\n",
    "    filename_suffix: str = \"posterior_pairs\",\n",
    "    dpi: int = 300,\n",
    "    show_legend: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    2×2 process-style pairplot:\n",
    "      TL: Y-marginal KDE per muscle\n",
    "      TR: joint scatter per muscle + per-muscle 2D KDE contours (darker color)\n",
    "          (if show_scatter=False: density-only with recursive fills of mass levels)\n",
    "      BL: legend (marker + line for each muscle)\n",
    "      BR: X-marginal KDE per muscle\n",
    "\n",
    "    dims_to_display must be [X_dim, Y_dim].\n",
    "\n",
    "    Smoothing:\n",
    "      - kde1d_bw: passed to scipy.stats.gaussian_kde(..., bw_method=...) for 1-D marginals\n",
    "      - kde2d_bw: same for 2-D joint KDE\n",
    "    \"\"\"\n",
    "    import os, re\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import to_rgb\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    from matplotlib.lines import Line2D\n",
    "    from scipy.stats import gaussian_kde\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _build_alias_maps(dim_aliases):\n",
    "        alias_to_canon = {}\n",
    "        canon_to_searchlist = {}\n",
    "        for canon, aliases in dim_aliases.items():\n",
    "            search = [canon] + list(aliases)\n",
    "            canon_to_searchlist[canon] = search\n",
    "            alias_to_canon[canon] = canon\n",
    "            for a in aliases:\n",
    "                alias_to_canon[a] = canon\n",
    "        return alias_to_canon, canon_to_searchlist\n",
    "\n",
    "    def _alias_columns_to_canonical(df, dim_aliases):\n",
    "        df = df.copy()\n",
    "        searchlists = {canon: [canon] + list(aliases)\n",
    "                       for canon, aliases in dim_aliases.items()}\n",
    "        for canon, search in searchlists.items():\n",
    "            present = [col for col in search if col in df.columns]\n",
    "            if not present:\n",
    "                df[canon] = np.nan\n",
    "            else:\n",
    "                df[canon] = df[present].bfill(axis=1).iloc[:, 0]\n",
    "        return df\n",
    "\n",
    "    def _robust_limits(arr, pad=0.05):\n",
    "        arr = np.asarray(arr, float)\n",
    "        arr = arr[np.isfinite(arr)]\n",
    "        if arr.size == 0:\n",
    "            return (0.0, 1.0)\n",
    "        lo = float(np.nanpercentile(arr, 1))\n",
    "        hi = float(np.nanpercentile(arr, 99))\n",
    "        if not np.isfinite(lo) or not np.isfinite(hi):\n",
    "            lo, hi = np.nanmin(arr), np.nanmax(arr)\n",
    "        if lo == hi:\n",
    "            lo, hi = lo - 0.5, hi + 0.5\n",
    "        span = hi - lo\n",
    "        return (lo - pad * span, hi + pad * span)\n",
    "\n",
    "    def _safe_kde_1d(x, grid, bw_method=None):\n",
    "        x = np.asarray(x, float)\n",
    "        x = x[np.isfinite(x)]\n",
    "        if x.size < 3 or np.nanstd(x) == 0:\n",
    "            return None\n",
    "        try:\n",
    "            kde = gaussian_kde(x, bw_method=bw_method)\n",
    "            return kde(grid)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _darker(hexcol: str, mix: float = 0.5):\n",
    "        r, g, b = to_rgb(hexcol)\n",
    "        m = np.clip(float(mix), 0.0, 1.0)\n",
    "        return (r*(1-m), g*(1-m), b*(1-m))\n",
    "\n",
    "    def _kde2d_norm(X, Y, xlim, ylim, grid_n=220, bw_method=None):\n",
    "        X = np.asarray(X, float); Y = np.asarray(Y, float)\n",
    "        mask = np.isfinite(X) & np.isfinite(Y)\n",
    "        X, Y = X[mask], Y[mask]\n",
    "        if X.size < 3 or np.nanstd(X) == 0 or np.nanstd(Y) == 0:\n",
    "            return None, None, None\n",
    "        gx = np.linspace(xlim[0], xlim[1], int(grid_n))\n",
    "        gy = np.linspace(ylim[0], ylim[1], int(grid_n))\n",
    "        XX, YY = np.meshgrid(gx, gy)\n",
    "        try:\n",
    "            kde = gaussian_kde(np.vstack([X, Y]), bw_method=bw_method)\n",
    "            dens = kde(np.vstack([XX.ravel(), YY.ravel()])).reshape(XX.shape)\n",
    "        except Exception:\n",
    "            return None, None, None\n",
    "        dmin, dmax = float(np.nanmin(dens)), float(np.nanmax(dens))\n",
    "        if not np.isfinite(dmin) or not np.isfinite(dmax) or dmax <= dmin:\n",
    "            return None, None, None\n",
    "        dens_norm = (dens - dmin) / (dmax - dmin)\n",
    "        return XX, YY, dens_norm\n",
    "\n",
    "    def _pretty_group_title(keys, vals):\n",
    "        if not keys: return \"All\"\n",
    "        if isinstance(vals, tuple): return \", \".join(f\"{k}={v!s}\" for k, v in zip(keys, vals))\n",
    "        return f\"{keys[0]}={vals!s}\"\n",
    "\n",
    "    def _fname_id(keys, vals):\n",
    "        if not keys: return \"all\"\n",
    "        if not isinstance(vals, tuple): vals = (vals,)\n",
    "        raw = \"_\".join(f\"{k}-{v}\" for k, v in zip(keys, vals))\n",
    "        return re.sub(r\"[^\\w\\-\\.]\", \"_\", raw)\n",
    "\n",
    "    # ---------- dims & aliasing ----------\n",
    "    if len(dims_to_display) != 2:\n",
    "        raise ValueError(\"dims_to_display must be exactly [X_dim, Y_dim].\")\n",
    "    X_req, Y_req = dims_to_display  # explicit: first is X (BR), second is Y (TL)\n",
    "\n",
    "    lims_by_dim = lims_by_dim or {}\n",
    "    alias_to_canon, _ = _build_alias_maps(dim_aliases)\n",
    "\n",
    "    bounds_by_canon = {}\n",
    "    for k, v in lims_by_dim.items():\n",
    "        canon_k = alias_to_canon.get(k, k)\n",
    "        bounds_by_canon[canon_k] = tuple(v)\n",
    "\n",
    "    df_c = _alias_columns_to_canonical(df, dim_aliases)\n",
    "\n",
    "    xdim_canon = alias_to_canon.get(X_req, X_req)\n",
    "    ydim_canon = alias_to_canon.get(Y_req, Y_req)\n",
    "    if xdim_canon not in df_c.columns or ydim_canon not in df_c.columns:\n",
    "        raise KeyError(f\"Requested dims not found after aliasing: {xdim_canon}, {ydim_canon}\")\n",
    "\n",
    "    # Build plot columns (normalized or raw)\n",
    "    def _prep_plot_col(d):\n",
    "        col = df_c[d].to_numpy(dtype=float)\n",
    "        if normalize_to_unit and (d in bounds_by_canon):\n",
    "            if assume_pre_normalized:\n",
    "                vals = col; lims = (0.0, 1.0)\n",
    "            else:\n",
    "                lo, hi = bounds_by_canon[d]\n",
    "                span = (hi - lo) if (hi > lo) else 1.0\n",
    "                vals = (col - lo) / span\n",
    "                lims = (0.0, 1.0)\n",
    "            return vals, lims\n",
    "        else:\n",
    "            vals = col\n",
    "            lims = _robust_limits(vals)\n",
    "            return vals, lims\n",
    "\n",
    "    xvals_all, xlims_def = _prep_plot_col(xdim_canon)\n",
    "    yvals_all, ylims_def = _prep_plot_col(ydim_canon)\n",
    "\n",
    "    xlim_use = xlims_def if xlim is None else xlim\n",
    "    ylim_use = ylims_def if ylim is None else ylim\n",
    "\n",
    "    # Grouping\n",
    "    if stratify_by:\n",
    "        grouped = df_c.assign(__x=xvals_all, __y=yvals_all).groupby(stratify_by, dropna=False)\n",
    "    else:\n",
    "        grouped = [((), df_c.assign(__x=xvals_all, __y=yvals_all))]\n",
    "\n",
    "    out_paths = []\n",
    "\n",
    "    # ---------- plotting per group ----------\n",
    "    for group_key, sub in grouped:\n",
    "        fig = plt.figure(figsize=(8.4, 8.4), constrained_layout=False)\n",
    "        gs  = GridSpec(2, 2, width_ratios=[1, 1], height_ratios=[1, 1],\n",
    "                       wspace=0.07, hspace=0.07, figure=fig)\n",
    "        ax_tl = fig.add_subplot(gs[0, 0])  # Y marginal (KDE)\n",
    "        ax_tr = fig.add_subplot(gs[0, 1])  # joint\n",
    "        ax_bl = fig.add_subplot(gs[1, 0])  # legend\n",
    "        ax_br = fig.add_subplot(gs[1, 1])  # X marginal (KDE)\n",
    "\n",
    "        hue_vals = list(sub[hue_by].dropna().unique())\n",
    "        hue_vals = [hv for hv in hue_vals if hv in muscle_colors]\n",
    "\n",
    "        gx = np.linspace(xlim_use[0], xlim_use[1], 300)\n",
    "        gy = np.linspace(ylim_use[0], ylim_use[1], 300)\n",
    "\n",
    "        # ---- TL: Y marginal KDEs ----\n",
    "        for hv in hue_vals:\n",
    "            col = muscle_colors[hv]\n",
    "            y = sub.loc[sub[hue_by]==hv, \"__y\"].to_numpy(dtype=float)\n",
    "            dens = _safe_kde_1d(y, gy, bw_method=kde1d_bw)\n",
    "            if dens is not None:\n",
    "                ax_tl.plot(gy, dens, color=col, lw=kde1d_lw, label=str(hv))\n",
    "        ax_tl.set_xlim(ylim_use[0], ylim_use[1])\n",
    "        ax_tl.set_xlabel(ydim_canon); ax_tl.set_ylabel(\"density\")\n",
    "        try: ax_tl.set_box_aspect(1)\n",
    "        except: pass\n",
    "\n",
    "        # ---- BR: X marginal KDEs ----\n",
    "        for hv in hue_vals:\n",
    "            col = muscle_colors[hv]\n",
    "            x = sub.loc[sub[hue_by]==hv, \"__x\"].to_numpy(dtype=float)\n",
    "            dens = _safe_kde_1d(x, gx, bw_method=kde1d_bw)\n",
    "            if dens is not None:\n",
    "                ax_br.plot(gx, dens, color=col, lw=kde1d_lw, label=str(hv))\n",
    "        ax_br.set_xlim(xlim_use[0], xlim_use[1])\n",
    "        ax_br.set_xlabel(xdim_canon); ax_br.set_ylabel(\"density\")\n",
    "        try: ax_br.set_box_aspect(1)\n",
    "        except: pass\n",
    "\n",
    "        # ---- TR: joint (scatter + 2D KDE) ----\n",
    "        levels_sorted_inc = tuple(sorted(kde2d_levels))\n",
    "        levels_sorted_dec = tuple(sorted(kde2d_levels, reverse=True))\n",
    "\n",
    "        for hv in hue_vals:\n",
    "            col = muscle_colors[hv]\n",
    "            x = sub.loc[sub[hue_by]==hv, \"__x\"].to_numpy(dtype=float)\n",
    "            y = sub.loc[sub[hue_by]==hv, \"__y\"].to_numpy(dtype=float)\n",
    "            m = np.isfinite(x) & np.isfinite(y)\n",
    "            if show_scatter and np.any(m):\n",
    "                ax_tr.scatter(x[m], y[m], s=point_size, c=col, edgecolor='none', alpha=scatter_alpha, label=str(hv))\n",
    "            XX, YY, densN = _kde2d_norm(x[m], y[m], xlim_use, ylim_use, grid_n=kde2d_grid, bw_method=kde2d_bw) if np.any(m) else (None, None, None)\n",
    "            if densN is not None:\n",
    "                dark = _darker(col, darker_mix)\n",
    "                if not show_scatter:\n",
    "                    for i, lev in enumerate(levels_sorted_dec):\n",
    "                        for _ in range(i+1):\n",
    "                            ax_tr.contourf(XX, YY, densN, levels=[lev, 1.01],\n",
    "                                           colors=[col], alpha=kde2d_fill_alpha, antialiased=True)\n",
    "                ax_tr.contour(XX, YY, densN, levels=levels_sorted_inc, colors=[dark],\n",
    "                              linewidths=kde2d_lw, alpha=kde2d_alpha)\n",
    "\n",
    "        ax_tr.set_xlim(xlim_use[0], xlim_use[1]); ax_tr.set_ylim(ylim_use[0], ylim_use[1])\n",
    "        ax_tr.set_xlabel(xdim_canon); ax_tr.set_ylabel(ydim_canon)\n",
    "        try: ax_tr.set_box_aspect(1)\n",
    "        except: pass\n",
    "\n",
    "        # ---- Legend ----\n",
    "        ax_bl.axis(\"off\")\n",
    "        if show_legend and hue_vals:\n",
    "            proxies, labels = [], []\n",
    "            for hv in hue_vals:\n",
    "                col = muscle_colors[hv]\n",
    "                if show_scatter:\n",
    "                    h = Line2D([0], [0], color=col, lw=2.0,\n",
    "                               marker='o', markersize=6, markerfacecolor=col, markeredgecolor='none')\n",
    "                else:\n",
    "                    h = Line2D([0], [0], color=col, lw=2.0)\n",
    "                proxies.append(h); labels.append(str(hv))\n",
    "            if proxies:\n",
    "                ax_bl.legend(proxies, labels, frameon=False, loc=\"center\", ncol=1)\n",
    "\n",
    "        title = _pretty_group_title(stratify_by or [], group_key)\n",
    "        fig.suptitle(title, y=0.98, fontsize=12)\n",
    "\n",
    "        fname_id = _fname_id(stratify_by or [], group_key)\n",
    "        out_svg = os.path.join(save_dir, f\"{filename_suffix}_{fname_id}.svg\")\n",
    "        fig.savefig(out_svg, dpi=dpi)\n",
    "        plt.show()\n",
    "        out_paths.append(out_svg)\n",
    "\n",
    "    return out_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa21e7",
   "metadata": {},
   "source": [
    "### Subjects pooled (what is reported in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e3e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_paths = multi_muscle_pairplot_scatter_kde(\n",
    "    df=df_pooled_subjects,\n",
    "    dim_aliases=dim_aliases,\n",
    "    dims_to_display=[\"common_input_std\", \"disynpatic_inhib_connections_desired_MN_MN\"],  # X, Y\n",
    "    hue_by=\"muscle\",\n",
    "    muscle_colors=colors_dict,\n",
    "    stratify_by=[\"intensity\"],\n",
    "    lims_by_dim=lims_by_dim,\n",
    "    # normalize_to_unit=True,\n",
    "    # assume_pre_normalized=True,\n",
    "    normalize_to_unit=False,\n",
    "    assume_pre_normalized=False,\n",
    "\n",
    "    # visuals\n",
    "    show_scatter=False,             # set False to see density-only with recursive fills\n",
    "    point_size=20,\n",
    "    scatter_alpha=0.01,\n",
    "    kde1d_lw=2,\n",
    "    kde2d_levels=(0.3, 0.6, 0.9),\n",
    "    kde2d_lw=1.4,\n",
    "    kde2d_alpha=1.0,\n",
    "    kde2d_grid=220,\n",
    "    darker_mix=0,\n",
    "    kde2d_fill_alpha=0.1,         # used only when show_scatter=False\n",
    "\n",
    "    # KDE smoothing ; larger values = smoother\n",
    "    # kde1d_bw=\"scott\", # \"scott\" or \"silverman\"\n",
    "    # kde2d_bw=\"scott\", # \"scott\" or \"silverman\"\n",
    "    kde1d_bw=0.2,          # manually specified bandwidth multiplier\n",
    "    kde2d_bw=0.2,          # manually specified bandwidth multiplier\n",
    "\n",
    "    save_dir=save_path,\n",
    "    filename_suffix=\"posterior_pairs_onlykde\",\n",
    "    dpi=300,\n",
    "    show_legend=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27028b7e",
   "metadata": {},
   "source": [
    "### Per-subject pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d902481",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_per_subject = f\"Posterior inference output figures\\\\Individual participants pairplots\"\n",
    "if not os.path.exists(save_path_per_subject):\n",
    "    os.mkdir(save_path_per_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_i in df_each_subject['subject'].unique():\n",
    "    print(f\"Processing {subject_i}...\")\n",
    "    df_temp = df_each_subject[df_each_subject['subject']==subject_i]\n",
    "    out_paths = multi_muscle_pairplot_scatter_kde(\n",
    "        df=df_temp,\n",
    "        dim_aliases=dim_aliases,\n",
    "        dims_to_display=[\"common_input_std\", \"disynpatic_inhib_connections_desired_MN_MN\"],  # X, Y\n",
    "        hue_by=\"muscle\",\n",
    "        muscle_colors=colors_dict,\n",
    "        stratify_by=[\"intensity\"],\n",
    "        lims_by_dim=lims_by_dim,\n",
    "        # normalize_to_unit=True,\n",
    "        # assume_pre_normalized=True,\n",
    "        normalize_to_unit=False,\n",
    "        assume_pre_normalized=False,\n",
    "\n",
    "        # visuals\n",
    "        show_scatter=False,             # set False to see density-only with recursive fills\n",
    "        point_size=20,\n",
    "        scatter_alpha=0.01,\n",
    "        kde1d_lw=2,\n",
    "        kde2d_levels=(0.3, 0.6, 0.9),\n",
    "        kde2d_lw=1.4,\n",
    "        kde2d_alpha=1.0,\n",
    "        kde2d_grid=220,\n",
    "        darker_mix=0,\n",
    "        kde2d_fill_alpha=0.1,         # used only when show_scatter=False\n",
    "\n",
    "        # KDE smoothing ; larger values = smoother\n",
    "        # kde1d_bw=\"scott\", # \"scott\" or \"silverman\"\n",
    "        # kde2d_bw=\"scott\", # \"scott\" or \"silverman\"\n",
    "        kde1d_bw=0.2,          # manually specified bandwidth multiplier\n",
    "        kde2d_bw=0.2,          # manually specified bandwidth multiplier\n",
    "\n",
    "        save_dir=save_path_per_subject,\n",
    "        filename_suffix=f\"{subject_i}_posterior\",\n",
    "        dpi=300,\n",
    "        show_legend=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8dc2b",
   "metadata": {},
   "source": [
    "# Pairwise between-muscles & between-intensity comparisons of posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from typing import Optional\n",
    "\n",
    "# --------- Column coalescing ----------\n",
    "def coalesce_param_series(\n",
    "    df: pd.DataFrame,\n",
    "    param: str,\n",
    "    dim_aliases: dict[str, list[str]] | None = None,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return a single Series with the parameter values, coalescing the canonical\n",
    "    column `param` and any alias columns listed in `dim_aliases[param]`.\n",
    "    If `param` is itself an alias in someone else's list, we also include those canonicals.\n",
    "    \"\"\"\n",
    "    candidates = [param]\n",
    "    if dim_aliases and param in dim_aliases:\n",
    "        candidates += dim_aliases[param]\n",
    "    if dim_aliases:\n",
    "        for canon, alist in dim_aliases.items():\n",
    "            if param in alist and canon not in candidates:\n",
    "                candidates.append(canon)\n",
    "    candidates = [c for c in candidates if c in df.columns]\n",
    "    if not candidates:\n",
    "        return pd.Series(index=df.index, dtype=float)\n",
    "    out = df[candidates[0]].copy()\n",
    "    for c in candidates[1:]:\n",
    "        out = out.where(~out.isna(), df[c])\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------- pδ at one intensity ----------\n",
    "def compare_groups_pdelta_at_intensity(\n",
    "    df: pd.DataFrame,\n",
    "    intensity: float,\n",
    "    param: str,\n",
    "    group_col: str = \"muscle_pair\",\n",
    "    min_samples: int = 1,\n",
    "    dim_aliases: dict[str, list[str]] | None = None,\n",
    "    drop_empty_groups: bool = False,\n",
    "    by_cols: list[str] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a given intensity, compute pΔ and 95% ETI for every UNORDERED pair of groups.\n",
    "    If `by_cols` is provided, comparisons are done within each stratum.\n",
    "    \"\"\"\n",
    "    df_i = df[df[\"intensity\"] == intensity].copy()\n",
    "    df_i[\"_param_eff\"] = coalesce_param_series(df_i, param, dim_aliases)\n",
    "    df_i = df_i[~df_i[\"_param_eff\"].isna()]\n",
    "\n",
    "    strata = df_i.groupby(by_cols, dropna=False) if by_cols else [((), df_i)]\n",
    "    out_rows = []\n",
    "    for skey, sub in strata:\n",
    "        if drop_empty_groups:\n",
    "            counts = sub.groupby(group_col)[\"_param_eff\"].size()\n",
    "            groups = [g for g, c in counts.items() if c >= min_samples]\n",
    "        else:\n",
    "            groups = sub[group_col].dropna().unique().tolist()\n",
    "\n",
    "        for A, B in itertools.combinations(sorted(groups), 2):\n",
    "            sampA = sub.loc[sub[group_col] == A, \"_param_eff\"].to_numpy()\n",
    "            sampB = sub.loc[sub[group_col] == B, \"_param_eff\"].to_numpy()\n",
    "            if len(sampA) < min_samples or len(sampB) < min_samples:\n",
    "                continue\n",
    "            n = min(len(sampA), len(sampB))\n",
    "            delta = sampA[:n] - sampB[:n]\n",
    "            p = float(np.mean(delta > 0))\n",
    "            lo, hi = np.percentile(delta, [2.5, 97.5])\n",
    "            row = {\n",
    "                \"intensity\": intensity,\n",
    "                \"group_A\": A, \"group_B\": B,\n",
    "                \"p_delta_pos\": p,\n",
    "                \"ci_lower\": lo, \"ci_upper\": hi,\n",
    "                \"nA\": int(len(sampA)), \"nB\": int(len(sampB)),\n",
    "            }\n",
    "            if by_cols:\n",
    "                if not isinstance(skey, tuple): skey = (skey,)\n",
    "                row.update({k: v for k, v in zip(by_cols, skey)})\n",
    "            out_rows.append(row)\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "# --------- Δd at one intensity ----------\n",
    "def _normalize_series_for_param(\n",
    "    s: pd.Series,\n",
    "    param: str,\n",
    "    *,\n",
    "    lims_by_dim: dict[str, tuple] | None = None,\n",
    "    normalize_to_unit: bool = False,\n",
    "    assume_pre_normalized: bool = False,\n",
    ") -> pd.Series:\n",
    "    if not normalize_to_unit:\n",
    "        return s.astype(float)\n",
    "    if assume_pre_normalized:\n",
    "        return s.astype(float)\n",
    "    if lims_by_dim is None or param not in lims_by_dim:\n",
    "        raise KeyError(f\"normalize_to_unit=True but no bounds for '{param}' in lims_by_dim.\")\n",
    "    lo, hi = lims_by_dim[param]\n",
    "    span = (hi - lo) if (hi > lo) else 1.0\n",
    "    return (s.astype(float) - lo) / span\n",
    "\n",
    "def compare_groups_deltad_at_intensity(\n",
    "    df: pd.DataFrame,\n",
    "    intensity: float,\n",
    "    param: str,\n",
    "    group_col: str = \"muscle_pair\",\n",
    "    dim_aliases: dict[str, list[str]] | None = None,\n",
    "    min_samples: int = 1,\n",
    "    drop_empty_groups: bool = False,\n",
    "    by_cols: list[str] | None = None,\n",
    "    *,\n",
    "\n",
    "    # normalization controls (same semantics as your pairplot code)\n",
    "    lims_by_dim: dict[str, tuple] | None = None,\n",
    "    normalize_to_unit: bool = False,\n",
    "    assume_pre_normalized: bool = False,\n",
    "\n",
    "    # Δd definition\n",
    "    delta_d_method: str = \"median_diff\",   # \"median_diff\" or \"hl\"\n",
    "    hl_max_pairs: int = 200_000,\n",
    "    hl_rng_seed: int = 0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a given intensity, compute Δd for every UNORDERED pair of groups.\n",
    "\n",
    "    delta_d_method:\n",
    "      - \"median_diff\": Δd(A,B) = median(A) − median(B)\n",
    "      - \"hl\":          Δd(A,B) = Hodges–Lehmann shift = median_{i,j}(a_i − b_j)\n",
    "\n",
    "    Optionally normalize values to 0–1 using lims_by_dim (prior bounds).\n",
    "    \"\"\"\n",
    "    df_i = df[df[\"intensity\"] == intensity].copy()\n",
    "    df_i[\"_param_eff\"] = coalesce_param_series(df_i, param, dim_aliases)\n",
    "    df_i = df_i[~df_i[\"_param_eff\"].isna()]\n",
    "    if df_i.empty:\n",
    "        return pd.DataFrame([])\n",
    "\n",
    "    # Normalized working column for Δd\n",
    "    df_i[\"__val\"] = _normalize_series_for_param(\n",
    "        df_i[\"_param_eff\"], param,\n",
    "        lims_by_dim=lims_by_dim,\n",
    "        normalize_to_unit=normalize_to_unit,\n",
    "        assume_pre_normalized=assume_pre_normalized,\n",
    "    )\n",
    "\n",
    "    strata = df_i.groupby(by_cols, dropna=False) if by_cols else [((), df_i)]\n",
    "    out_rows = []\n",
    "\n",
    "    for skey, sub in strata:\n",
    "        # eligible groups\n",
    "        if drop_empty_groups:\n",
    "            counts = sub.groupby(group_col)[\"__val\"].size()\n",
    "            groups = [g for g, c in counts.items() if c >= min_samples]\n",
    "        else:\n",
    "            groups = sub[group_col].dropna().unique().tolist()\n",
    "\n",
    "        # per-group arrays (finite) and medians\n",
    "        arrays = {\n",
    "            g: sub.loc[sub[group_col] == g, \"__val\"].to_numpy(float)\n",
    "            for g in groups\n",
    "        }\n",
    "        arrays = {g: v[np.isfinite(v)] for g, v in arrays.items()}\n",
    "        med = {g: (np.nanmedian(v) if v.size else np.nan) for g, v in arrays.items()}\n",
    "        n   = {g: int(arrays[g].size) for g in arrays.keys()}\n",
    "\n",
    "        groups = sorted([g for g in groups if n[g] >= min_samples])\n",
    "\n",
    "        for A, B in itertools.combinations(groups, 2):\n",
    "            if n[A] < min_samples or n[B] < min_samples:\n",
    "                continue\n",
    "\n",
    "            if delta_d_method == \"hl\":\n",
    "                val = hodges_lehmann(arrays[A], arrays[B],\n",
    "                                     max_pairs=hl_max_pairs, rng_seed=hl_rng_seed)\n",
    "            else:  # \"median_diff\"\n",
    "                val = float(med[A] - med[B])\n",
    "\n",
    "            row = {\n",
    "                \"intensity\": intensity,\n",
    "                \"group_A\": A, \"group_B\": B,\n",
    "                \"delta_d\": val,\n",
    "                \"median_A\": float(med[A]) if np.isfinite(med[A]) else np.nan,\n",
    "                \"median_B\": float(med[B]) if np.isfinite(med[B]) else np.nan,\n",
    "                \"nA\": n[A], \"nB\": n[B],\n",
    "            }\n",
    "            if by_cols:\n",
    "                if not isinstance(skey, tuple): skey = (skey,)\n",
    "                row.update({k: v for k, v in zip(by_cols, skey)})\n",
    "            out_rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "# --------- intensity strip: pδ high vs low ----------\n",
    "def compare_intensities_for_group(\n",
    "    df: pd.DataFrame,\n",
    "    group_value: str,\n",
    "    param: str,\n",
    "    group_col: str = \"muscle_pair\",\n",
    "    low_intensity: float | None = None,\n",
    "    high_intensity: float | None = None,\n",
    "    min_samples: int = 1,\n",
    "    dim_aliases: dict[str, list[str]] | None = None,\n",
    "    skip_if_missing: bool = False,\n",
    "    by_filters: dict[str, object] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    P( high > low ), as you already had.\n",
    "    \"\"\"\n",
    "    sub = df[df[group_col] == group_value].copy()\n",
    "    if by_filters:\n",
    "        for k, v in by_filters.items():\n",
    "            sub = sub[sub[k] == v]\n",
    "    sub[\"_param_eff\"] = coalesce_param_series(sub, param, dim_aliases)\n",
    "    sub = sub[~sub[\"_param_eff\"].isna()]\n",
    "\n",
    "    ints = sorted(sub[\"intensity\"].unique())\n",
    "    if (low_intensity is None) or (high_intensity is None):\n",
    "        if len(ints) < 2:\n",
    "            if skip_if_missing:\n",
    "                return pd.DataFrame([])\n",
    "            return pd.DataFrame([{\n",
    "                group_col: group_value, \"intensity_low\": np.nan, \"intensity_high\": np.nan,\n",
    "                \"p_delta_pos\": np.nan, \"ci_lower\": np.nan, \"ci_upper\": np.nan,\n",
    "                \"n_low\": 0, \"n_high\": 0, **(by_filters or {})\n",
    "            }])\n",
    "        low_intensity, high_intensity = min(ints), max(ints)\n",
    "\n",
    "    samp_low  = sub.loc[sub[\"intensity\"] == low_intensity,  \"_param_eff\"].to_numpy()\n",
    "    samp_high = sub.loc[sub[\"intensity\"] == high_intensity, \"_param_eff\"].to_numpy()\n",
    "    if len(samp_low) < min_samples or len(samp_high) < min_samples:\n",
    "        if skip_if_missing:\n",
    "            return pd.DataFrame([])\n",
    "        return pd.DataFrame([{\n",
    "            group_col: group_value,\n",
    "            \"intensity_low\": low_intensity, \"intensity_high\": high_intensity,\n",
    "            \"p_delta_pos\": np.nan, \"ci_lower\": np.nan, \"ci_upper\": np.nan,\n",
    "            \"n_low\": int(len(samp_low)), \"n_high\": int(len(samp_high)),\n",
    "            **(by_filters or {})\n",
    "        }])\n",
    "\n",
    "    n = min(len(samp_low), len(samp_high))\n",
    "    delta = samp_high[:n] - samp_low[:n]\n",
    "    p = float(np.mean(delta > 0))\n",
    "    lo, hi = np.percentile(delta, [2.5, 97.5])\n",
    "    row = {\n",
    "        group_col: group_value,\n",
    "        \"intensity_low\": low_intensity,\n",
    "        \"intensity_high\": high_intensity,\n",
    "        \"p_delta_pos\": p, \"ci_lower\": lo, \"ci_upper\": hi,\n",
    "        \"n_low\": int(len(samp_low)), \"n_high\": int(len(samp_high)),\n",
    "    }\n",
    "    if by_filters:\n",
    "        row.update(by_filters)\n",
    "    return pd.DataFrame([row])\n",
    "\n",
    "# --------- Hodges–Lehmann estimator (median of pairwise differences) ----------\n",
    "def hodges_lehmann(x, y, max_pairs=200_000, rng_seed=0):\n",
    "    \"\"\"\n",
    "    HL(x,y) = median_{i,j} (x_i - y_j).\n",
    "    Exact if len(x)*len(y) <= max_pairs; otherwise uses a random subset of pairs.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float); x = x[np.isfinite(x)]\n",
    "    y = np.asarray(y, float); y = y[np.isfinite(y)]\n",
    "    if x.size == 0 or y.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    total_pairs = x.size * y.size\n",
    "    if total_pairs <= max_pairs:\n",
    "        diffs = (x[:, None] - y[None, :]).ravel()\n",
    "        return float(np.median(diffs))\n",
    "\n",
    "    # Subsample ~max_pairs pairs via independent index sampling\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    k = int(np.sqrt(max_pairs))\n",
    "    ix = rng.integers(0, x.size, size=k)\n",
    "    iy = rng.integers(0, y.size, size=k)\n",
    "    diffs = x[ix][:, None] - y[iy][None, :]\n",
    "    return float(np.median(diffs))\n",
    "\n",
    "\n",
    "# --------- Intensity strip: Δd (high vs low) with selectable definition ----------\n",
    "def compare_intensities_deltad_for_group(\n",
    "    df: pd.DataFrame,\n",
    "    group_value: str,\n",
    "    param: str,\n",
    "    group_col: str = \"muscle_pair\",\n",
    "    low_intensity: float | None = None,\n",
    "    high_intensity: float | None = None,\n",
    "    min_samples: int = 1,\n",
    "    dim_aliases: dict[str, list[str]] | None = None,\n",
    "    skip_if_missing: bool = False,\n",
    "    by_filters: dict[str, object] | None = None,\n",
    "    *,\n",
    "    # normalization controls (same semantics as your pairplot code)\n",
    "    lims_by_dim: dict[str, tuple] | None = None,\n",
    "    normalize_to_unit: bool = False,\n",
    "    assume_pre_normalized: bool = False,\n",
    "    # Δd definition\n",
    "    delta_d_method: str = \"median_diff\",   # \"median_diff\" or \"hl\"\n",
    "    hl_max_pairs: int = 200_000,\n",
    "    hl_rng_seed: int = 0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute Δd between the high and low intensity distributions for a single group.\n",
    "\n",
    "    delta_d_method:\n",
    "      - \"median_diff\": Δd = median(high) − median(low)\n",
    "      - \"hl\":          Δd = Hodges–Lehmann shift = median_{i,j}(high_i − low_j)\n",
    "\n",
    "    Normalization:\n",
    "      If normalize_to_unit=True and lims_by_dim contains bounds for `param`,\n",
    "      values are mapped to [0,1]. If assume_pre_normalized=True, values are\n",
    "      used as-is but axes/bounds are conceptually [0,1].\n",
    "    \"\"\"\n",
    "    sub = df[df[group_col] == group_value].copy()\n",
    "    if by_filters:\n",
    "        for k, v in by_filters.items():\n",
    "            sub = sub[sub[k] == v]\n",
    "\n",
    "    # Coalesce param column(s) per your helper\n",
    "    sub[\"_param_eff\"] = coalesce_param_series(sub, param, dim_aliases)\n",
    "    sub = sub[~sub[\"_param_eff\"].isna()]\n",
    "\n",
    "    # Pick intensities if not given\n",
    "    ints = sorted(sub[\"intensity\"].unique())\n",
    "    if (low_intensity is None) or (high_intensity is None):\n",
    "        if len(ints) < 2:\n",
    "            if skip_if_missing:\n",
    "                return pd.DataFrame([])\n",
    "            return pd.DataFrame([{\n",
    "                group_col: group_value, \"intensity_low\": np.nan, \"intensity_high\": np.nan,\n",
    "                \"delta_d\": np.nan, \"n_low\": 0, \"n_high\": 0, **(by_filters or {})\n",
    "            }])\n",
    "        low_intensity, high_intensity = min(ints), max(ints)\n",
    "\n",
    "    # Normalize working copy (expects your _normalize_series_for_param helper to exist)\n",
    "    sub[\"__val\"] = _normalize_series_for_param(\n",
    "        sub[\"_param_eff\"], param,\n",
    "        lims_by_dim=lims_by_dim,\n",
    "        normalize_to_unit=normalize_to_unit,\n",
    "        assume_pre_normalized=assume_pre_normalized,\n",
    "    )\n",
    "\n",
    "    # Extract finite arrays for each intensity\n",
    "    v_low  = sub.loc[sub[\"intensity\"] == low_intensity,  \"__val\"].to_numpy(dtype=float)\n",
    "    v_high = sub.loc[sub[\"intensity\"] == high_intensity, \"__val\"].to_numpy(dtype=float)\n",
    "    v_low  = v_low[np.isfinite(v_low)]\n",
    "    v_high = v_high[np.isfinite(v_high)]\n",
    "\n",
    "    n_low  = int(v_low.size)\n",
    "    n_high = int(v_high.size)\n",
    "    if n_low < min_samples or n_high < min_samples:\n",
    "        if skip_if_missing:\n",
    "            return pd.DataFrame([])\n",
    "        return pd.DataFrame([{\n",
    "            group_col: group_value,\n",
    "            \"intensity_low\": low_intensity, \"intensity_high\": high_intensity,\n",
    "            \"delta_d\": np.nan, \"n_low\": n_low, \"n_high\": n_high,\n",
    "            **(by_filters or {})\n",
    "        }])\n",
    "\n",
    "    # Compute Δd with the selected method (sign = high − low)\n",
    "    if delta_d_method == \"hl\":\n",
    "        dval = hodges_lehmann(v_high, v_low, max_pairs=hl_max_pairs, rng_seed=hl_rng_seed)\n",
    "    else:  # \"median_diff\"\n",
    "        dval = float(np.nanmedian(v_high) - np.nanmedian(v_low))\n",
    "\n",
    "    row = {\n",
    "        group_col: group_value,\n",
    "        \"intensity_low\": low_intensity, \"intensity_high\": high_intensity,\n",
    "        \"delta_d\": dval, \"n_low\": n_low, \"n_high\": n_high,\n",
    "    }\n",
    "    if by_filters:\n",
    "        row.update(by_filters)\n",
    "    return pd.DataFrame([row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05164c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, TwoSlopeNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_pairwise_heatmaps_single_metric(\n",
    "    *,\n",
    "    df_low: pd.DataFrame,         # pairwise comparisons at low intensity (e.g., 10%)\n",
    "    df_high: pd.DataFrame,        # pairwise comparisons at high intensity (e.g., 40%)\n",
    "    df_intensity: pd.DataFrame,   # per-group comparisons high vs low (strip)\n",
    "    metric_col: str,              # 'p_delta_pos' or 'delta_d'\n",
    "    metric_label: str,            # e.g., \"pδ = P(row > col)\" or \"Δd = median(row) − median(col)\"\n",
    "    pair_col_A: str = \"group_A\",\n",
    "    pair_col_B: str = \"group_B\",\n",
    "    # groups / labels / colors\n",
    "    group_values: list[str] | None = None,\n",
    "    display_map: dict[str, str] | None = None,\n",
    "    muscle_colors: dict[str, str] | None = None,\n",
    "    group_col_label: str = \"group\",\n",
    "    mp_col_in_strip: str | None = None,     # column in df_intensity that holds the group id\n",
    "    intensity_strip_label: str = \"High vs Low\",\n",
    "    # symmetry fill for the opposite triangle (optional)\n",
    "    symmetric_fill: bool = True,            # fill M[B,A] too\n",
    "    symmetric_rule: str | None = None,      # None|'one_minus'|'negate'|'copy'  (auto if None)\n",
    "    # color scaling\n",
    "    cmap: str = \"RdBu_r\",\n",
    "    vmin: float | None = None,\n",
    "    vmax: float | None = None,\n",
    "    vcenter: float | None = None,           # set 0 for Δd; None for pδ; or 0.5 for pδ if you want diverging\n",
    "    # layout\n",
    "    title_low: str = \"Low intensity\",\n",
    "    title_high: str = \"High intensity\",\n",
    "    figsize=(24, 10),\n",
    "    savepath: str = \".\",\n",
    "    savename_suffix: str = \"\",\n",
    "    title_suffix: str = \"\",\n",
    "    dpi: int = 300,\n",
    "    annotate: bool = True,\n",
    "    annotate_fontsize: int = 11,\n",
    "    annotate_fontweight: str = \"regular\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Draws ONE metric (pδ or Δd) for (low, high) + an intensity strip using the same metric.\n",
    "    Robust to having (B,A) present but not (A,B): mirrors via symmetric_rule to avoid NaNs.\n",
    "    \"\"\"\n",
    "    # --- derive group list from inputs if not given\n",
    "    def _nonan_unique(x):\n",
    "        return pd.Series(x).dropna().unique().tolist()\n",
    "\n",
    "    pair_groups = set(_nonan_unique(df_low.get(pair_col_A, [])))  \\\n",
    "                | set(_nonan_unique(df_low.get(pair_col_B, [])))  \\\n",
    "                | set(_nonan_unique(df_high.get(pair_col_A, []))) \\\n",
    "                | set(_nonan_unique(df_high.get(pair_col_B, [])))\n",
    "\n",
    "    # strip group id column\n",
    "    if mp_col_in_strip is None:\n",
    "        candidates = [c for c in df_intensity.columns\n",
    "                      if c not in {\"intensity_low\",\"intensity_high\",\n",
    "                                   \"p_delta_pos\",\"delta_d\",\"ci_lower\",\"ci_upper\",\n",
    "                                   \"n_low\",\"n_high\"}]\n",
    "        mp_col_in_strip = candidates[0] if candidates else \"group\"\n",
    "    strip_groups = set(_nonan_unique(df_intensity.get(mp_col_in_strip, [])))\n",
    "\n",
    "    all_groups_present = sorted(pair_groups | strip_groups)\n",
    "    if group_values is None:\n",
    "        mps = all_groups_present\n",
    "    else:\n",
    "        mps = [g for g in group_values if g in all_groups_present]\n",
    "\n",
    "    disp = {g: (display_map[g] if display_map and g in display_map else g) for g in mps}\n",
    "\n",
    "    # --- symmetric rule auto default\n",
    "    if symmetric_rule is None:\n",
    "        symmetric_rule = 'one_minus' if metric_col == \"p_delta_pos\" else 'negate'\n",
    "\n",
    "    # --- build square matrix; accept rows in either direction and mirror if needed\n",
    "    def make_matrix_bi(df_pairwise: pd.DataFrame) -> pd.DataFrame:\n",
    "        M = pd.DataFrame(np.nan, index=mps, columns=mps)\n",
    "        if df_pairwise is None or df_pairwise.empty:\n",
    "            # diagonal default\n",
    "            np.fill_diagonal(M.values, 0.5 if metric_col == \"p_delta_pos\" else 0.0)\n",
    "            return M\n",
    "\n",
    "        # Insert all provided (A,B)\n",
    "        for _, row in df_pairwise.iterrows():\n",
    "            A = row.get(pair_col_A, None)\n",
    "            B = row.get(pair_col_B, None)\n",
    "            val = row.get(metric_col, np.nan)\n",
    "            if (A in M.index) and (B in M.columns) and pd.notna(val):\n",
    "                M.at[A, B] = float(val)\n",
    "\n",
    "        # Now mirror where only the reverse exists:\n",
    "        n = len(M.index)\n",
    "        for i, A in enumerate(mps):\n",
    "            for j, B in enumerate(mps):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                vAB = M.at[A, B]\n",
    "                vBA = M.at[B, A]\n",
    "                # if only reverse is present, fill forward using the rule's inverse\n",
    "                if pd.isna(vAB) and pd.notna(vBA):\n",
    "                    if symmetric_rule == 'one_minus':\n",
    "                        M.at[A, B] = 1.0 - float(vBA)\n",
    "                    elif symmetric_rule == 'negate':\n",
    "                        M.at[A, B] = -float(vBA)\n",
    "                    else:  # 'copy'\n",
    "                        M.at[A, B] = float(vBA)\n",
    "\n",
    "        # Finally, if asked, fill the other triangle from what we now have\n",
    "        if symmetric_fill:\n",
    "            for i, A in enumerate(mps):\n",
    "                for j, B in enumerate(mps):\n",
    "                    if i >= j:\n",
    "                        continue\n",
    "                    vAB = M.at[A, B]\n",
    "                    vBA = M.at[B, A]\n",
    "                    if pd.notna(vAB):\n",
    "                        if symmetric_rule == 'one_minus':\n",
    "                            M.at[B, A] = 1.0 - float(vAB)\n",
    "                        elif symmetric_rule == 'negate':\n",
    "                            M.at[B, A] = -float(vAB)\n",
    "                        else:\n",
    "                            M.at[B, A] = float(vAB)\n",
    "                    elif pd.notna(vBA):\n",
    "                        if symmetric_rule == 'one_minus':\n",
    "                            M.at[A, B] = 1.0 - float(vBA)\n",
    "                        elif symmetric_rule == 'negate':\n",
    "                            M.at[A, B] = -float(vBA)\n",
    "                        else:\n",
    "                            M.at[A, B] = float(vBA)\n",
    "\n",
    "        # diagonal defaults\n",
    "        np.fill_diagonal(M.values, 0.5 if metric_col == \"p_delta_pos\" else 0.0)\n",
    "        return M\n",
    "\n",
    "    Mlow  = make_matrix_bi(df_low)\n",
    "    Mhigh = make_matrix_bi(df_high)\n",
    "\n",
    "    # --- color scaling (include strip values if using diverging)\n",
    "    cmap_obj = plt.get_cmap(cmap).copy()\n",
    "    cmap_obj.set_bad(\"lightgrey\")\n",
    "\n",
    "    if vcenter is None:\n",
    "        # pδ-like in [0,1]\n",
    "        if vmin is None: vmin = 0.0\n",
    "        if vmax is None: vmax = 1.0\n",
    "        norm = Normalize(vmin, vmax)\n",
    "    else:\n",
    "        # Δd-like → diverging; auto symmetric if vmin/vmax not given\n",
    "        if vmin is None or vmax is None:\n",
    "            vals = []\n",
    "            for M in (Mlow.values, Mhigh.values):\n",
    "                arr = np.asarray(M, float)\n",
    "                arr = arr[np.isfinite(arr)]\n",
    "                if arr.size:\n",
    "                    vals.append(arr)\n",
    "            # include strip too (same metric)\n",
    "            strip_vals = df_intensity.set_index(mp_col_in_strip)[metric_col].reindex(mps).to_numpy(float)\n",
    "            strip_vals = strip_vals[np.isfinite(strip_vals)]\n",
    "            if strip_vals.size:\n",
    "                vals.append(strip_vals)\n",
    "            if vals:\n",
    "                allv = np.concatenate(vals)\n",
    "                bound = float(np.nanmax(np.abs(allv))) if allv.size else 1.0\n",
    "            else:\n",
    "                bound = 1.0\n",
    "            vmin, vmax = -bound, +bound\n",
    "        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "\n",
    "    # --- figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "    def draw_panel(ax, M: pd.DataFrame, title_text: str):\n",
    "        im = ax.imshow(M.values, cmap=cmap_obj, norm=norm, origin=\"lower\")\n",
    "        ax.invert_xaxis()\n",
    "        ax.set_xticks(np.arange(len(mps)))\n",
    "        ax.set_xticklabels([disp[g] for g in mps], rotation=90, weight=\"bold\")\n",
    "        ax.set_yticks(np.arange(len(mps)))\n",
    "        ax.set_yticklabels([disp[g] for g in mps], weight=\"bold\")\n",
    "        ax.set_xlabel(f\"... compared to this {group_col_label}?\")\n",
    "        ax.set_ylabel(f\"This {group_col_label} ...\")\n",
    "        ax.set_title(title_text)\n",
    "        if muscle_colors:\n",
    "            for lbl in ax.get_xticklabels():\n",
    "                lbl.set_color(muscle_colors.get(lbl.get_text(), \"grey\"))\n",
    "            for lbl in ax.get_yticklabels():\n",
    "                lbl.set_color(muscle_colors.get(lbl.get_text(), \"grey\"))\n",
    "        if annotate:\n",
    "            for i in range(len(mps)):\n",
    "                for j in range(len(mps)):\n",
    "                    v = M.iat[i, j]\n",
    "                    if pd.isna(v): \n",
    "                        continue\n",
    "                    # if metric_col == \"p_delta_pos\":\n",
    "                    #     # stars near extremes\n",
    "                    #     star = \"★\" if (v > 0.95 or v < 0.05) else \"\"\n",
    "                    #     txt = f\"{v:.2f}{star}\"\n",
    "                    #     color = \"white\" if abs(v - 0.5) > 0.25 else \"black\"\n",
    "                    # else:\n",
    "                    txt = f\"{v:.2f}\"\n",
    "                    vmax_abs = max(abs(getattr(norm, \"vmin\", -1.0)), abs(getattr(norm, \"vmax\", 1.0)))\n",
    "                    # color = \"white\" if abs(v) > 0.8 * vmax_abs else \"black\"\n",
    "                    if metric_col == \"p_delta_pos\":\n",
    "                        color = \"white\" if abs(v - 0.5) > 0.25 else \"black\"\n",
    "                    else: \n",
    "                        color = \"black\"\n",
    "                    ax.text(j, i, txt, ha=\"center\", va=\"center\",\n",
    "                    fontsize=annotate_fontsize, fontweight=annotate_fontweight, color=color)\n",
    "        return im\n",
    "\n",
    "    im_low  = draw_panel(axes[0], Mlow,  title_low)\n",
    "    im_high = draw_panel(axes[1], Mhigh, title_high)\n",
    "\n",
    "    # --- strip panel — same metric (and annotated)\n",
    "    ax = axes[2]\n",
    "    strip_series = df_intensity.set_index(mp_col_in_strip)[metric_col].reindex(mps)\n",
    "    col = strip_series.values.reshape(-1, 1)\n",
    "    im_strip = ax.imshow(col, cmap=cmap_obj, norm=norm, origin=\"lower\")\n",
    "    ax.set_xticks([0]); ax.set_xticklabels([intensity_strip_label], weight=\"bold\")\n",
    "    ax.set_yticks(np.arange(len(mps))); ax.set_yticklabels([disp[g] for g in mps], weight=\"bold\")\n",
    "    ax.set_title(f\"{intensity_strip_label} — {metric_label}\")\n",
    "    if muscle_colors:\n",
    "        for lbl in ax.get_yticklabels():\n",
    "            lbl.set_color(muscle_colors.get(lbl.get_text(), \"grey\"))\n",
    "    if annotate:\n",
    "        for i, v in enumerate(strip_series):\n",
    "            if pd.isna(v): \n",
    "                continue\n",
    "            # if metric_col == \"p_delta_pos\":\n",
    "            #     star = \"★\" if (v > 0.95 or v < 0.05) else \"\"\n",
    "            #     txt = f\"{v:.2f}{star}\"\n",
    "            #     color = \"white\" if abs(v - 0.5) > 0.25 else \"black\"\n",
    "            # else:\n",
    "            txt = f\"{v:.2f}\"\n",
    "            vmax_abs = max(abs(getattr(norm, \"vmin\", -1.0)), abs(getattr(norm, \"vmax\", 1.0)))\n",
    "            if metric_col == \"p_delta_pos\":\n",
    "                color = \"white\" if abs(v - 0.5) > 0.25 else \"black\"\n",
    "            else: \n",
    "                color = \"black\"\n",
    "            ax.text(0, i, txt, ha=\"center\", va=\"center\",\n",
    "                    fontsize=annotate_fontsize, fontweight=annotate_fontweight, color=color)\n",
    "\n",
    "    # --- colorbar\n",
    "    cax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(ScalarMappable(norm=norm, cmap=cmap_obj), cax=cax, label=metric_label)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "    if title_suffix:\n",
    "        plt.suptitle(title_suffix, fontsize=15, y=1.02)\n",
    "\n",
    "    if savepath and savepath != \".\":\n",
    "        fn = f\"pairwise_heatmaps_{metric_col}_{title_suffix.replace(' ','_')}_{savename_suffix}\"\n",
    "        fig.savefig(f\"{savepath}/{fn}.png\", bbox_inches=\"tight\", dpi=dpi)\n",
    "        fig.savefig(f\"{savepath}/{fn}.svg\", bbox_inches=\"tight\", dpi=dpi)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72821b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual diverging colormap helper function\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap, to_rgb\n",
    "def make_diverging_cmap_from_lists(\n",
    "    color_min_list,\n",
    "    color_max_list,\n",
    "    color_mid=\"#FFFFFF\",\n",
    "    *,\n",
    "    name=\"custom_div_from_lists\",\n",
    "    bad_color=\"lightgrey\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a smooth diverging colormap that interpolates linearly:\n",
    "        color_min_list[0] -> ... -> color_min_list[-1] -> color_mid (at 0.5)\n",
    "        -> color_max_list[0] -> ... -> color_max_list[-1]\n",
    "\n",
    "    The midpoint color is *exactly* at 0.5 even if left/right lists have different lengths.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    color_min_list : list[str]     # e.g. [\"blue\", \"cyan\"]\n",
    "    color_max_list : list[str]     # e.g. [\"orange\", \"red\"]\n",
    "    color_mid      : str           # e.g. \"white\"\n",
    "    name           : str           # colormap name (for debugging/registration)\n",
    "    bad_color      : str           # color for NaNs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.colors.LinearSegmentedColormap\n",
    "    \"\"\"\n",
    "    # sanitize inputs\n",
    "    color_min_list = list(color_min_list or [])\n",
    "    color_max_list = list(color_max_list or [])\n",
    "\n",
    "    if not color_min_list and not color_max_list:\n",
    "        raise ValueError(\"Provide at least one color on either side.\")\n",
    "\n",
    "    stops = []\n",
    "    cols  = []\n",
    "\n",
    "    # Left side: spread evenly in [0, 0.5), excluding 0.5\n",
    "    nL = len(color_min_list)\n",
    "    if nL > 0:\n",
    "        left_pos = np.linspace(0.0, 0.5, nL + 1, endpoint=True)[:-1]  # nL stops, last < 0.5\n",
    "        stops.extend(left_pos.tolist())\n",
    "        cols.extend(color_min_list)\n",
    "\n",
    "    # Midpoint exactly at 0.5\n",
    "    stops.append(0.5)\n",
    "    cols.append(color_mid)\n",
    "\n",
    "    # Right side: spread evenly in (0.5, 1], excluding 0.5\n",
    "    nR = len(color_max_list)\n",
    "    if nR > 0:\n",
    "        right_pos = np.linspace(0.5, 1.0, nR + 1, endpoint=True)[1:]  # nR stops, first > 0.5\n",
    "        stops.extend(right_pos.tolist())\n",
    "        cols.extend(color_max_list)\n",
    "\n",
    "    # Build colormap\n",
    "    cmap = LinearSegmentedColormap.from_list(name, list(zip(stops, cols)))\n",
    "    cmap.set_bad(bad_color)\n",
    "    return cmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f626607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inputs\n",
    "param_to_use = \"disynpatic_inhib_connections_desired_MN_MN\" # \"common_input_std\"\n",
    "# param_to_use = \"common_input_std\"\n",
    "group_col    = \"muscle\"\n",
    "int_low, int_high = 10.0, 40.0\n",
    "\n",
    "cmap_pdelta = make_diverging_cmap_from_lists(\n",
    "        color_min_list=[\"#3C5FD4\", \"#65A9F7\"],\n",
    "        color_max_list=[\"#FF9B8E\", \"#DF463B\"],\n",
    "        color_mid=\"#FFFFFF\")\n",
    "    # cmr.prinsenvlag_r\n",
    "    # \"RdBu_r\"  # pδ in [0,1]\n",
    "cmap_deltad = make_diverging_cmap_from_lists(\n",
    "    color_min_list=[\"#AF46C4\", \"#D87EDB\"],\n",
    "    color_max_list=[\"#FFD856\", \"#FFAE00\"],\n",
    "    color_mid=\"#FFFFFF\") # \"PuOr_r\" # Δd in [-max,+max]\n",
    "    ### ### Choose delta method ### ### \n",
    "    # hodges_lehmann HL(x,y) = median_{i,j} (x_i - y_j) => More robust\n",
    "    # delta_d_method=\"hl\", hl_max_pairs=200_000, hl_rng_seed=0\n",
    "    ### or use \"median_diff\" for median(high)-median(low)\n",
    "delta_d_method = \"median_diff\"  # \"median_diff\" or \"hl\"\n",
    "annotate_fontsize = 18\n",
    "annotate_fontweight = \"regular\"\n",
    "\n",
    "df_use = df_all_posteriors[df_all_posteriors[\"level\"] == \"subjects_aggregated\"].copy()\n",
    "\n",
    "# Order & labels\n",
    "all_groups = sorted(df_use[group_col].unique())\n",
    "group_vals = [g for g in order_display.keys() if g in all_groups]\n",
    "group_vals = [g for g in group_vals if g in colors_dict]\n",
    "# reverse order (y-axis top-to-bottom and x axis left-to-right)\n",
    "group_vals = list(reversed(group_vals))\n",
    "disp_map   = {g: order_display[g] for g in group_vals}\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# A) pδ metric\n",
    "# -------------------------------\n",
    "df_pdelta_low  = compare_groups_pdelta_at_intensity(\n",
    "    df=df_use, intensity=int_low, param=param_to_use,\n",
    "    group_col=group_col, dim_aliases=dim_aliases,\n",
    "    min_samples=1, drop_empty_groups=True\n",
    ")\n",
    "df_pdelta_high = compare_groups_pdelta_at_intensity(\n",
    "    df=df_use, intensity=int_high, param=param_to_use,\n",
    "    group_col=group_col, dim_aliases=dim_aliases,\n",
    "    min_samples=1, drop_empty_groups=True\n",
    ")\n",
    "df_pdelta_strip = pd.concat([\n",
    "    compare_intensities_for_group(\n",
    "        df_use, g, param=param_to_use, group_col=group_col,\n",
    "        low_intensity=int_low, high_intensity=int_high,\n",
    "        dim_aliases=dim_aliases, skip_if_missing=True\n",
    "    ) for g in group_vals\n",
    "], ignore_index=True).rename(columns={group_col: \"group\"})\n",
    "\n",
    "plot_pairwise_heatmaps_single_metric(\n",
    "    df_low=df_pdelta_low,\n",
    "    df_high=df_pdelta_high,\n",
    "    df_intensity=df_pdelta_strip,\n",
    "    metric_col=\"p_delta_pos\",\n",
    "    metric_label=\"pδ = P(row > col)\",\n",
    "    pair_col_A=\"group_A\", pair_col_B=\"group_B\",\n",
    "    group_values=group_vals,\n",
    "    display_map=disp_map,\n",
    "    muscle_colors=colors_dict,\n",
    "    group_col_label=(\"pair\" if group_col==\"muscle_pair\" else \"direction\"),\n",
    "    mp_col_in_strip=\"group\",\n",
    "    symmetric_fill=True,            # also fills upper triangle with 1-p\n",
    "    symmetric_rule=\"one_minus\",\n",
    "    cmap=cmap_pdelta,\n",
    "    vmin=0.0, vmax=1.0, vcenter=None,\n",
    "    title_low=\"10%\", title_high=\"40%\",\n",
    "    savepath=save_path,\n",
    "    title_suffix=f\"{param_to_use} — pdelta ({group_col})\",\n",
    "    annotate_fontsize=annotate_fontsize,\n",
    "    annotate_fontweight=annotate_fontweight\n",
    ")\n",
    "\n",
    "if delta_d_method == \"median_diff\":\n",
    "    metric_label_deltad = \"Δd = median(row) − median(col)\"\n",
    "else:\n",
    "    metric_label_deltad = \"Δd = Hodges–Lehmann (median_{i,j} (x_i - y_j))\"\n",
    "# -------------------------------\n",
    "# B) Δd metric (raw or normalized)\n",
    "# -------------------------------\n",
    "# choose normalization mode:\n",
    "USE_NORMALIZED = True  # set False for raw units\n",
    "df_deltad_low  = compare_groups_deltad_at_intensity(\n",
    "    df=df_use, intensity=int_low, param=param_to_use,\n",
    "    group_col=group_col, dim_aliases=dim_aliases,\n",
    "    min_samples=1, drop_empty_groups=True,\n",
    "    lims_by_dim=lims_by_dim,                   # only needed if normalize=True\n",
    "    normalize_to_unit=USE_NORMALIZED,\n",
    "    assume_pre_normalized=True,               # True if your DF already in [0,1]\n",
    "    ### ### Choose delta method ### ### \n",
    "    # hodges_lehmann HL(x,y) = median_{i,j} (x_i - y_j) => More robust\n",
    "    # delta_d_method=\"hl\", hl_max_pairs=200_000, hl_rng_seed=0\n",
    "    ### or use \"median_diff\" for median(high)-median(low)\n",
    "    delta_d_method=delta_d_method\n",
    ")\n",
    "df_deltad_high = compare_groups_deltad_at_intensity(\n",
    "    df=df_use, intensity=int_high, param=param_to_use,\n",
    "    group_col=group_col, dim_aliases=dim_aliases,\n",
    "    min_samples=1, drop_empty_groups=True,\n",
    "    lims_by_dim=lims_by_dim,\n",
    "    normalize_to_unit=USE_NORMALIZED,\n",
    "    assume_pre_normalized=True,\n",
    "    ### ### Choose delta method ### ### \n",
    "    # hodges_lehmann HL(x,y) = median_{i,j} (x_i - y_j) => More robust\n",
    "    # delta_d_method=\"hl\", hl_max_pairs=200_000, hl_rng_seed=0\n",
    "    ### or use \"median_diff\" for median(high)-median(low)\n",
    "    delta_d_method=delta_d_method\n",
    ")\n",
    "df_deltad_strip = pd.concat([\n",
    "    compare_intensities_deltad_for_group(\n",
    "        df_use, g, param=param_to_use, group_col=group_col,\n",
    "        low_intensity=int_low, high_intensity=int_high,\n",
    "        dim_aliases=dim_aliases, skip_if_missing=True,\n",
    "        lims_by_dim=lims_by_dim,\n",
    "        normalize_to_unit=USE_NORMALIZED,\n",
    "        assume_pre_normalized=True,\n",
    "    ) for g in group_vals\n",
    "], ignore_index=True).rename(columns={group_col: \"group\"})\n",
    "\n",
    "plot_pairwise_heatmaps_single_metric(\n",
    "    df_low=df_deltad_low,\n",
    "    df_high=df_deltad_high,\n",
    "    df_intensity=df_deltad_strip,\n",
    "    metric_col=f\"delta_d\",\n",
    "    metric_label=metric_label_deltad,\n",
    "    pair_col_A=\"group_A\", pair_col_B=\"group_B\",\n",
    "    group_values=group_vals,\n",
    "    display_map=disp_map,\n",
    "    muscle_colors=colors_dict,\n",
    "    group_col_label=(\"pair\" if group_col==\"muscle_pair\" else \"direction\"),\n",
    "    mp_col_in_strip=\"group\",\n",
    "    symmetric_fill=True,            # fills upper triangle with −Δd\n",
    "    symmetric_rule=\"negate\",\n",
    "    cmap=cmap_deltad,                    # pick any diverging colormap\n",
    "    # vcenter=0.0, vmin=None, vmax=None,  # auto symmetric ±max|Δd|\n",
    "    vcenter=0.0, vmin=-0.5, vmax=0.5,  # auto symmetric ±max|Δd|\n",
    "    title_low=\"10%\", title_high=\"40%\",\n",
    "    savepath=save_path,\n",
    "    title_suffix=f\"{param_to_use} — deltad ({group_col}) - {delta_d_method}\",\n",
    "    annotate_fontsize=annotate_fontsize,\n",
    "    annotate_fontweight=annotate_fontweight\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapping_RI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
